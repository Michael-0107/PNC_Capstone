{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Use version 1.x not 2.x\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    records = []\n",
    "    for company, periods in data.items():\n",
    "        for period, (features, rating, normed_rating) in periods.items():\n",
    "            record = {\n",
    "                'company': company,\n",
    "                'period': period,\n",
    "                **{f'feature_{i}': feature.item() for i, feature in enumerate(features)},\n",
    "                'rating': rating.item(),\n",
    "                'normed_rating': normed_rating.item()\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"Ret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import importlib\n",
    "import os\n",
    "import Hypers\n",
    "importlib.reload(Hypers)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_Ret.pkl')\n",
    "test_df = load_data('./data/test_dict_Ret.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_144</th>\n",
       "      <th>feature_145</th>\n",
       "      <th>feature_146</th>\n",
       "      <th>feature_147</th>\n",
       "      <th>feature_148</th>\n",
       "      <th>feature_149</th>\n",
       "      <th>feature_150</th>\n",
       "      <th>feature_151</th>\n",
       "      <th>rating</th>\n",
       "      <th>normed_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.187263</td>\n",
       "      <td>3.672922</td>\n",
       "      <td>3.328550</td>\n",
       "      <td>3.678313</td>\n",
       "      <td>3.535753</td>\n",
       "      <td>3.178305</td>\n",
       "      <td>4.632567</td>\n",
       "      <td>3.200210</td>\n",
       "      <td>3.447581</td>\n",
       "      <td>3.510239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922653</td>\n",
       "      <td>0.285270</td>\n",
       "      <td>-0.128237</td>\n",
       "      <td>0.454483</td>\n",
       "      <td>0.217197</td>\n",
       "      <td>-0.195160</td>\n",
       "      <td>0.121779</td>\n",
       "      <td>231.538452</td>\n",
       "      <td>3.437243</td>\n",
       "      <td>0.312477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.122091</td>\n",
       "      <td>10.115408</td>\n",
       "      <td>9.168132</td>\n",
       "      <td>11.502782</td>\n",
       "      <td>11.037309</td>\n",
       "      <td>8.630302</td>\n",
       "      <td>14.841910</td>\n",
       "      <td>7.309015</td>\n",
       "      <td>9.044514</td>\n",
       "      <td>9.708005</td>\n",
       "      <td>...</td>\n",
       "      <td>23.838283</td>\n",
       "      <td>3.215718</td>\n",
       "      <td>9.729554</td>\n",
       "      <td>9.677379</td>\n",
       "      <td>2.809457</td>\n",
       "      <td>47.856759</td>\n",
       "      <td>1.573591</td>\n",
       "      <td>7.286771</td>\n",
       "      <td>1.173064</td>\n",
       "      <td>0.106642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.301897</td>\n",
       "      <td>-0.266775</td>\n",
       "      <td>-0.288342</td>\n",
       "      <td>-0.295740</td>\n",
       "      <td>-0.291449</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>-0.281195</td>\n",
       "      <td>-0.187304</td>\n",
       "      <td>-0.224620</td>\n",
       "      <td>-48.201126</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.857426</td>\n",
       "      <td>-8.556656</td>\n",
       "      <td>-210.371216</td>\n",
       "      <td>-21.627665</td>\n",
       "      <td>-6.615319</td>\n",
       "      <td>-2797.750244</td>\n",
       "      <td>-6.860989</td>\n",
       "      <td>215.350998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.045383</td>\n",
       "      <td>0.165266</td>\n",
       "      <td>0.138738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117887</td>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.193609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321555</td>\n",
       "      <td>-0.264877</td>\n",
       "      <td>-0.455649</td>\n",
       "      <td>-0.276370</td>\n",
       "      <td>-0.341851</td>\n",
       "      <td>-0.652883</td>\n",
       "      <td>-0.388726</td>\n",
       "      <td>226.421005</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.881459</td>\n",
       "      <td>0.879826</td>\n",
       "      <td>0.908394</td>\n",
       "      <td>0.509373</td>\n",
       "      <td>0.769879</td>\n",
       "      <td>0.830885</td>\n",
       "      <td>0.898819</td>\n",
       "      <td>0.933667</td>\n",
       "      <td>0.941483</td>\n",
       "      <td>0.748759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003799</td>\n",
       "      <td>-0.004444</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>-0.007522</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>-0.002089</td>\n",
       "      <td>233.546005</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.406673</td>\n",
       "      <td>2.694911</td>\n",
       "      <td>2.579666</td>\n",
       "      <td>2.902219</td>\n",
       "      <td>2.623788</td>\n",
       "      <td>2.706648</td>\n",
       "      <td>3.098006</td>\n",
       "      <td>2.705751</td>\n",
       "      <td>2.756163</td>\n",
       "      <td>2.922812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379047</td>\n",
       "      <td>0.358832</td>\n",
       "      <td>0.373275</td>\n",
       "      <td>0.471599</td>\n",
       "      <td>0.440151</td>\n",
       "      <td>0.489981</td>\n",
       "      <td>0.474075</td>\n",
       "      <td>237.432999</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124.559494</td>\n",
       "      <td>123.289658</td>\n",
       "      <td>119.041771</td>\n",
       "      <td>169.197495</td>\n",
       "      <td>154.960480</td>\n",
       "      <td>124.026894</td>\n",
       "      <td>197.495544</td>\n",
       "      <td>87.117142</td>\n",
       "      <td>114.921547</td>\n",
       "      <td>153.907394</td>\n",
       "      <td>...</td>\n",
       "      <td>1789.264038</td>\n",
       "      <td>192.869949</td>\n",
       "      <td>245.542419</td>\n",
       "      <td>618.762756</td>\n",
       "      <td>80.971764</td>\n",
       "      <td>1347.325928</td>\n",
       "      <td>30.387802</td>\n",
       "      <td>242.839005</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0    feature_1    feature_2    feature_3    feature_4  \\\n",
       "count  6079.000000  6079.000000  6079.000000  6079.000000  6079.000000   \n",
       "mean      3.187263     3.672922     3.328550     3.678313     3.535753   \n",
       "std       9.122091    10.115408     9.168132    11.502782    11.037309   \n",
       "min      -0.301897    -0.266775    -0.288342    -0.295740    -0.291449   \n",
       "25%       0.045383     0.165266     0.138738     0.000000     0.110582   \n",
       "50%       0.881459     0.879826     0.908394     0.509373     0.769879   \n",
       "75%       2.406673     2.694911     2.579666     2.902219     2.623788   \n",
       "max     124.559494   123.289658   119.041771   169.197495   154.960480   \n",
       "\n",
       "         feature_5    feature_6    feature_7    feature_8    feature_9  ...  \\\n",
       "count  6079.000000  6079.000000  6079.000000  6079.000000  6079.000000  ...   \n",
       "mean      3.178305     4.632567     3.200210     3.447581     3.510239  ...   \n",
       "std       8.630302    14.841910     7.309015     9.044514     9.708005  ...   \n",
       "min      -0.222196    -0.281195    -0.187304    -0.224620   -48.201126  ...   \n",
       "25%       0.000000     0.117887     0.196239     0.193609     0.000000  ...   \n",
       "50%       0.830885     0.898819     0.933667     0.941483     0.748759  ...   \n",
       "75%       2.706648     3.098006     2.705751     2.756163     2.922812  ...   \n",
       "max     124.026894   197.495544    87.117142   114.921547   153.907394  ...   \n",
       "\n",
       "       feature_144  feature_145  feature_146  feature_147  feature_148  \\\n",
       "count  6079.000000  6079.000000  6079.000000  6079.000000  6079.000000   \n",
       "mean      0.922653     0.285270    -0.128237     0.454483     0.217197   \n",
       "std      23.838283     3.215718     9.729554     9.677379     2.809457   \n",
       "min     -14.857426    -8.556656  -210.371216   -21.627665    -6.615319   \n",
       "25%      -0.321555    -0.264877    -0.455649    -0.276370    -0.341851   \n",
       "50%      -0.003799    -0.004444     0.019302     0.028620    -0.007522   \n",
       "75%       0.379047     0.358832     0.373275     0.471599     0.440151   \n",
       "max    1789.264038   192.869949   245.542419   618.762756    80.971764   \n",
       "\n",
       "       feature_149  feature_150  feature_151       rating  normed_rating  \n",
       "count  6079.000000  6079.000000  6079.000000  6079.000000    6079.000000  \n",
       "mean     -0.195160     0.121779   231.538452     3.437243       0.312477  \n",
       "std      47.856759     1.573591     7.286771     1.173064       0.106642  \n",
       "min   -2797.750244    -6.860989   215.350998     0.000000       0.000000  \n",
       "25%      -0.652883    -0.388726   226.421005     3.000000       0.272727  \n",
       "50%      -0.058273    -0.002089   233.546005     3.000000       0.272727  \n",
       "75%       0.489981     0.474075   237.432999     4.000000       0.363636  \n",
       "max    1347.325928    30.387802   242.839005    10.000000       0.909091  \n",
       "\n",
       "[8 rows x 154 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.4015  MSE=0.0098\n",
      "Random Forest       : Accuracy=0.4992  MSE=0.0059\n",
      "Linear Regression   : Accuracy=0.4587  MSE=0.0066\n",
      "k-NN (k=1)          : Accuracy=0.3484  MSE=0.0113\n",
      "SVR                 : Accuracy=0.5244  MSE=0.0058\n",
      "XGBoost             : Accuracy=0.4929  MSE=0.0065\n",
      "LightGBM            : Accuracy=0.5102  MSE=0.0057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import Hypers\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'k-NN (k=1)': KNeighborsRegressor(n_neighbors=1),\n",
    "    'SVR': SVR(),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=RANDOM_SEED, verbose=-1)\n",
    "}\n",
    "\n",
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"RetInd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_RetInd.pkl')\n",
    "test_df = load_data('./data/test_dict_RetInd.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.4647  MSE=0.0092\n",
      "Random Forest       : Accuracy=0.5684  MSE=0.0056\n",
      "Linear Regression   : Accuracy=0.4593  MSE=0.0145\n",
      "k-NN (k=1)          : Accuracy=0.3725  MSE=0.0114\n",
      "SVR                 : Accuracy=0.4885  MSE=0.0066\n",
      "XGBoost             : Accuracy=0.5169  MSE=0.0060\n",
      "LightGBM            : Accuracy=0.5952  MSE=0.0053\n"
     ]
    }
   ],
   "source": [
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_US.pkl')\n",
    "test_df = load_data('./data/test_dict_US.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.4646  MSE=0.0104\n",
      "Random Forest       : Accuracy=0.5497  MSE=0.0046\n",
      "Linear Regression   : Accuracy=0.4473  MSE=0.0070\n",
      "k-NN (k=1)          : Accuracy=0.3757  MSE=0.0121\n",
      "SVR                 : Accuracy=0.4803  MSE=0.0061\n",
      "XGBoost             : Accuracy=0.5292  MSE=0.0053\n",
      "LightGBM            : Accuracy=0.5573  MSE=0.0047\n"
     ]
    }
   ],
   "source": [
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
