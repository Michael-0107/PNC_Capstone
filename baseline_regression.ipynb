{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Use version 1.x not 2.x\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    records = []\n",
    "    for company, periods in data.items():\n",
    "        for period, (features, rating, normed_rating) in periods.items():\n",
    "            record = {\n",
    "                'company': company,\n",
    "                'period': period,\n",
    "                **{f'feature_{i}': feature.item() for i, feature in enumerate(features)},\n",
    "                'rating': rating.item(),\n",
    "                'normed_rating': normed_rating.item()\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"Ret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import importlib\n",
    "import os\n",
    "import Hypers\n",
    "importlib.reload(Hypers)\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_Ret.pkl')\n",
    "test_df = load_data('./data/test_dict_Ret.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_144</th>\n",
       "      <th>feature_145</th>\n",
       "      <th>feature_146</th>\n",
       "      <th>feature_147</th>\n",
       "      <th>feature_148</th>\n",
       "      <th>feature_149</th>\n",
       "      <th>feature_150</th>\n",
       "      <th>feature_151</th>\n",
       "      <th>rating</th>\n",
       "      <th>normed_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.594831</td>\n",
       "      <td>0.577020</td>\n",
       "      <td>0.591411</td>\n",
       "      <td>0.653195</td>\n",
       "      <td>0.774548</td>\n",
       "      <td>0.536094</td>\n",
       "      <td>0.621724</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>0.481432</td>\n",
       "      <td>0.436503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554901</td>\n",
       "      <td>0.170350</td>\n",
       "      <td>0.458713</td>\n",
       "      <td>0.214132</td>\n",
       "      <td>0.106362</td>\n",
       "      <td>-0.048175</td>\n",
       "      <td>0.051097</td>\n",
       "      <td>231.042954</td>\n",
       "      <td>3.160458</td>\n",
       "      <td>0.287314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.038298</td>\n",
       "      <td>1.113754</td>\n",
       "      <td>1.124720</td>\n",
       "      <td>1.759639</td>\n",
       "      <td>1.492708</td>\n",
       "      <td>0.873233</td>\n",
       "      <td>1.129207</td>\n",
       "      <td>1.005302</td>\n",
       "      <td>1.020033</td>\n",
       "      <td>1.389351</td>\n",
       "      <td>...</td>\n",
       "      <td>2.740273</td>\n",
       "      <td>1.290153</td>\n",
       "      <td>8.675437</td>\n",
       "      <td>2.164138</td>\n",
       "      <td>1.183531</td>\n",
       "      <td>2.015263</td>\n",
       "      <td>1.433077</td>\n",
       "      <td>7.451931</td>\n",
       "      <td>1.030405</td>\n",
       "      <td>0.093673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.451154</td>\n",
       "      <td>-0.337230</td>\n",
       "      <td>-0.444340</td>\n",
       "      <td>-0.447085</td>\n",
       "      <td>-0.444327</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>-0.393110</td>\n",
       "      <td>-0.345999</td>\n",
       "      <td>-0.485700</td>\n",
       "      <td>-11.514503</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.829387</td>\n",
       "      <td>-4.550150</td>\n",
       "      <td>-86.946945</td>\n",
       "      <td>-8.108098</td>\n",
       "      <td>-2.701822</td>\n",
       "      <td>-15.393591</td>\n",
       "      <td>-3.806167</td>\n",
       "      <td>216.177002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.084466</td>\n",
       "      <td>-0.079193</td>\n",
       "      <td>-0.127887</td>\n",
       "      <td>-0.345208</td>\n",
       "      <td>-0.178480</td>\n",
       "      <td>-0.074121</td>\n",
       "      <td>-0.090574</td>\n",
       "      <td>-0.135876</td>\n",
       "      <td>-0.201700</td>\n",
       "      <td>-0.291585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256378</td>\n",
       "      <td>-0.447852</td>\n",
       "      <td>-0.470640</td>\n",
       "      <td>-0.441947</td>\n",
       "      <td>-0.404765</td>\n",
       "      <td>-0.540801</td>\n",
       "      <td>-0.469965</td>\n",
       "      <td>226.421005</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.099123</td>\n",
       "      <td>0.035303</td>\n",
       "      <td>0.081214</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.146916</td>\n",
       "      <td>0.118784</td>\n",
       "      <td>0.082683</td>\n",
       "      <td>0.062017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.027230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058788</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>-0.057903</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>233.546005</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.207945</td>\n",
       "      <td>0.784976</td>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.819140</td>\n",
       "      <td>1.020126</td>\n",
       "      <td>1.045798</td>\n",
       "      <td>1.124965</td>\n",
       "      <td>0.601573</td>\n",
       "      <td>0.812106</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654815</td>\n",
       "      <td>0.571663</td>\n",
       "      <td>0.512019</td>\n",
       "      <td>0.461521</td>\n",
       "      <td>0.492112</td>\n",
       "      <td>0.449534</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>237.432999</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.246325</td>\n",
       "      <td>5.965914</td>\n",
       "      <td>5.264041</td>\n",
       "      <td>15.109673</td>\n",
       "      <td>7.858496</td>\n",
       "      <td>3.119110</td>\n",
       "      <td>7.442028</td>\n",
       "      <td>4.626092</td>\n",
       "      <td>5.416079</td>\n",
       "      <td>8.654183</td>\n",
       "      <td>...</td>\n",
       "      <td>26.717739</td>\n",
       "      <td>8.815295</td>\n",
       "      <td>130.894943</td>\n",
       "      <td>46.763088</td>\n",
       "      <td>7.141855</td>\n",
       "      <td>32.851486</td>\n",
       "      <td>10.174973</td>\n",
       "      <td>242.839005</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_0   feature_1   feature_2   feature_3   feature_4   feature_5  \\\n",
       "count  698.000000  698.000000  698.000000  698.000000  698.000000  698.000000   \n",
       "mean     0.594831    0.577020    0.591411    0.653195    0.774548    0.536094   \n",
       "std      1.038298    1.113754    1.124720    1.759639    1.492708    0.873233   \n",
       "min     -0.451154   -0.337230   -0.444340   -0.447085   -0.444327   -0.467565   \n",
       "25%     -0.084466   -0.079193   -0.127887   -0.345208   -0.178480   -0.074121   \n",
       "50%      0.099123    0.035303    0.081214    0.016288    0.070168    0.146916   \n",
       "75%      1.207945    0.784976    0.953786    0.819140    1.020126    1.045798   \n",
       "max      6.246325    5.965914    5.264041   15.109673    7.858496    3.119110   \n",
       "\n",
       "        feature_6   feature_7   feature_8   feature_9  ...  feature_144  \\\n",
       "count  698.000000  698.000000  698.000000  698.000000  ...   698.000000   \n",
       "mean     0.621724    0.500771    0.481432    0.436503  ...     0.554901   \n",
       "std      1.129207    1.005302    1.020033    1.389351  ...     2.740273   \n",
       "min     -0.393110   -0.345999   -0.485700  -11.514503  ...    -6.829387   \n",
       "25%     -0.090574   -0.135876   -0.201700   -0.291585  ...    -0.256378   \n",
       "50%      0.118784    0.082683    0.062017    0.000000  ...    -0.002702   \n",
       "75%      1.124965    0.601573    0.812106    0.683331  ...     0.654815   \n",
       "max      7.442028    4.626092    5.416079    8.654183  ...    26.717739   \n",
       "\n",
       "       feature_145  feature_146  feature_147  feature_148  feature_149  \\\n",
       "count   698.000000   698.000000   698.000000   698.000000   698.000000   \n",
       "mean      0.170350     0.458713     0.214132     0.106362    -0.048175   \n",
       "std       1.290153     8.675437     2.164138     1.183531     2.015263   \n",
       "min      -4.550150   -86.946945    -8.108098    -2.701822   -15.393591   \n",
       "25%      -0.447852    -0.470640    -0.441947    -0.404765    -0.540801   \n",
       "50%      -0.027230     0.000000    -0.058788     0.001524    -0.057903   \n",
       "75%       0.571663     0.512019     0.461521     0.492112     0.449534   \n",
       "max       8.815295   130.894943    46.763088     7.141855    32.851486   \n",
       "\n",
       "       feature_150  feature_151      rating  normed_rating  \n",
       "count   698.000000   698.000000  698.000000     698.000000  \n",
       "mean      0.051097   231.042954    3.160458       0.287314  \n",
       "std       1.433077     7.451931    1.030405       0.093673  \n",
       "min      -3.806167   216.177002    1.000000       0.090909  \n",
       "25%      -0.469965   226.421005    2.000000       0.181818  \n",
       "50%       0.006696   233.546005    3.000000       0.272727  \n",
       "75%       0.521937   237.432999    4.000000       0.363636  \n",
       "max      10.174973   242.839005    6.000000       0.545455  \n",
       "\n",
       "[8 rows x 154 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.3757  MSE=0.0138\n",
      "Random Forest       : Accuracy=0.1850  MSE=0.0114\n",
      "Linear Regression   : Accuracy=0.4162  MSE=1556506.3367\n",
      "k-NN (k=1)          : Accuracy=0.4682  MSE=0.0070\n",
      "SVR                 : Accuracy=0.4451  MSE=0.0101\n",
      "XGBoost             : Accuracy=0.1445  MSE=0.0124\n",
      "LightGBM            : Accuracy=0.2312  MSE=0.0120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import Hypers\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'k-NN (k=1)': KNeighborsRegressor(n_neighbors=1),\n",
    "    'SVR': SVR(),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=RANDOM_SEED, verbose=-1)\n",
    "}\n",
    "\n",
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"RetInd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_RetInd.pkl')\n",
    "test_df = load_data('./data/test_dict_RetInd.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.4315  MSE=0.0102\n",
      "Random Forest       : Accuracy=0.5136  MSE=0.0054\n",
      "Linear Regression   : Accuracy=0.4640  MSE=0.0161\n",
      "k-NN (k=1)          : Accuracy=0.3777  MSE=0.0135\n",
      "SVR                 : Accuracy=0.5013  MSE=0.0075\n",
      "XGBoost             : Accuracy=0.5408  MSE=0.0052\n",
      "LightGBM            : Accuracy=0.5583  MSE=0.0048\n"
     ]
    }
   ],
   "source": [
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = utils.load_pickle(os.path.join(Hypers.Config.data_path, f\"dataset_{suffix}.pkl\"))\n",
    "_, _ = utils.spilt_train_valid(merged_dict, random_select=True, save=True, suffix=suffix)\n",
    "\n",
    "train_df = load_data('./data/train_dict_US.pkl')\n",
    "test_df = load_data('./data/test_dict_US.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.4627  MSE=0.0126\n",
      "Random Forest       : Accuracy=0.5577  MSE=0.0080\n",
      "Linear Regression   : Accuracy=0.3959  MSE=0.0146\n",
      "k-NN (k=1)          : Accuracy=0.3701  MSE=0.0155\n",
      "SVR                 : Accuracy=0.4492  MSE=0.0112\n",
      "XGBoost             : Accuracy=0.5220  MSE=0.0076\n",
      "LightGBM            : Accuracy=0.5565  MSE=0.0074\n"
     ]
    }
   ],
   "source": [
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
