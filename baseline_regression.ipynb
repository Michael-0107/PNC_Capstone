{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Use version 1.x not 2.x\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    records = []\n",
    "    for company, periods in data.items():\n",
    "        for period, (features, rating, normed_rating) in periods.items():\n",
    "            record = {\n",
    "                'company': company,\n",
    "                'period': period,\n",
    "                **{f'feature_{i}': feature.item() for i, feature in enumerate(features)},\n",
    "                'rating': rating.item(),\n",
    "                'normed_rating': normed_rating.item()\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df = load_data('./data/train_dict_Ret.pkl')\n",
    "test_df = load_data('./data/test_dict_Ret.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_144</th>\n",
       "      <th>feature_145</th>\n",
       "      <th>feature_146</th>\n",
       "      <th>feature_147</th>\n",
       "      <th>feature_148</th>\n",
       "      <th>feature_149</th>\n",
       "      <th>feature_150</th>\n",
       "      <th>feature_151</th>\n",
       "      <th>rating</th>\n",
       "      <th>normed_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "      <td>6486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.246928</td>\n",
       "      <td>3.728670</td>\n",
       "      <td>3.383585</td>\n",
       "      <td>3.972089</td>\n",
       "      <td>3.588717</td>\n",
       "      <td>3.370097</td>\n",
       "      <td>4.758087</td>\n",
       "      <td>3.341170</td>\n",
       "      <td>3.574972</td>\n",
       "      <td>3.235445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903552</td>\n",
       "      <td>0.278248</td>\n",
       "      <td>-0.178201</td>\n",
       "      <td>0.422307</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.122311</td>\n",
       "      <td>0.126640</td>\n",
       "      <td>231.566921</td>\n",
       "      <td>3.499075</td>\n",
       "      <td>0.318098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.624939</td>\n",
       "      <td>10.081845</td>\n",
       "      <td>9.294818</td>\n",
       "      <td>12.750276</td>\n",
       "      <td>10.998795</td>\n",
       "      <td>10.161258</td>\n",
       "      <td>15.387909</td>\n",
       "      <td>7.617698</td>\n",
       "      <td>9.434874</td>\n",
       "      <td>9.430610</td>\n",
       "      <td>...</td>\n",
       "      <td>23.086153</td>\n",
       "      <td>3.103153</td>\n",
       "      <td>10.451794</td>\n",
       "      <td>9.162645</td>\n",
       "      <td>2.723020</td>\n",
       "      <td>47.460380</td>\n",
       "      <td>1.560399</td>\n",
       "      <td>7.289107</td>\n",
       "      <td>1.115911</td>\n",
       "      <td>0.101446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.301897</td>\n",
       "      <td>-0.266775</td>\n",
       "      <td>-0.288342</td>\n",
       "      <td>-0.295740</td>\n",
       "      <td>-0.291449</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>-0.281195</td>\n",
       "      <td>-0.187304</td>\n",
       "      <td>-0.224620</td>\n",
       "      <td>-48.201126</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.857426</td>\n",
       "      <td>-8.556656</td>\n",
       "      <td>-255.759018</td>\n",
       "      <td>-21.627665</td>\n",
       "      <td>-6.615319</td>\n",
       "      <td>-2797.750244</td>\n",
       "      <td>-6.860989</td>\n",
       "      <td>215.350998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.159972</td>\n",
       "      <td>0.148766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068408</td>\n",
       "      <td>0.205878</td>\n",
       "      <td>0.193514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306885</td>\n",
       "      <td>-0.261664</td>\n",
       "      <td>-0.506588</td>\n",
       "      <td>-0.286805</td>\n",
       "      <td>-0.346466</td>\n",
       "      <td>-0.617545</td>\n",
       "      <td>-0.391814</td>\n",
       "      <td>226.421005</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.827545</td>\n",
       "      <td>0.886593</td>\n",
       "      <td>0.521010</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.712322</td>\n",
       "      <td>0.833698</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.896203</td>\n",
       "      <td>0.637072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001913</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>-0.007045</td>\n",
       "      <td>-0.064847</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>233.546005</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.248683</td>\n",
       "      <td>2.838332</td>\n",
       "      <td>2.526265</td>\n",
       "      <td>2.654461</td>\n",
       "      <td>2.639659</td>\n",
       "      <td>2.583004</td>\n",
       "      <td>3.127944</td>\n",
       "      <td>2.877039</td>\n",
       "      <td>2.917653</td>\n",
       "      <td>2.831687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373598</td>\n",
       "      <td>0.354352</td>\n",
       "      <td>0.393931</td>\n",
       "      <td>0.463040</td>\n",
       "      <td>0.452260</td>\n",
       "      <td>0.468566</td>\n",
       "      <td>0.481544</td>\n",
       "      <td>237.432999</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124.559494</td>\n",
       "      <td>123.289658</td>\n",
       "      <td>119.041771</td>\n",
       "      <td>169.197495</td>\n",
       "      <td>154.960480</td>\n",
       "      <td>124.026894</td>\n",
       "      <td>197.495544</td>\n",
       "      <td>87.117142</td>\n",
       "      <td>114.921547</td>\n",
       "      <td>153.907394</td>\n",
       "      <td>...</td>\n",
       "      <td>1789.264038</td>\n",
       "      <td>192.869949</td>\n",
       "      <td>344.349670</td>\n",
       "      <td>618.762756</td>\n",
       "      <td>80.971764</td>\n",
       "      <td>1347.325928</td>\n",
       "      <td>30.387802</td>\n",
       "      <td>242.839005</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0    feature_1    feature_2    feature_3    feature_4  \\\n",
       "count  6486.000000  6486.000000  6486.000000  6486.000000  6486.000000   \n",
       "mean      3.246928     3.728670     3.383585     3.972089     3.588717   \n",
       "std       9.624939    10.081845     9.294818    12.750276    10.998795   \n",
       "min      -0.301897    -0.266775    -0.288342    -0.295740    -0.291449   \n",
       "25%       0.038195     0.159972     0.148766     0.000000     0.077618   \n",
       "50%       0.834705     0.827545     0.886593     0.521010     0.731387   \n",
       "75%       2.248683     2.838332     2.526265     2.654461     2.639659   \n",
       "max     124.559494   123.289658   119.041771   169.197495   154.960480   \n",
       "\n",
       "         feature_5    feature_6    feature_7    feature_8    feature_9  ...  \\\n",
       "count  6486.000000  6486.000000  6486.000000  6486.000000  6486.000000  ...   \n",
       "mean      3.370097     4.758087     3.341170     3.574972     3.235445  ...   \n",
       "std      10.161258    15.387909     7.617698     9.434874     9.430610  ...   \n",
       "min      -0.222196    -0.281195    -0.187304    -0.224620   -48.201126  ...   \n",
       "25%       0.000000     0.068408     0.205878     0.193514     0.000000  ...   \n",
       "50%       0.712322     0.833698     0.911647     0.896203     0.637072  ...   \n",
       "75%       2.583004     3.127944     2.877039     2.917653     2.831687  ...   \n",
       "max     124.026894   197.495544    87.117142   114.921547   153.907394  ...   \n",
       "\n",
       "       feature_144  feature_145  feature_146  feature_147  feature_148  \\\n",
       "count  6486.000000  6486.000000  6486.000000  6486.000000  6486.000000   \n",
       "mean      0.903552     0.278248    -0.178201     0.422307     0.209412   \n",
       "std      23.086153     3.103153    10.451794     9.162645     2.723020   \n",
       "min     -14.857426    -8.556656  -255.759018   -21.627665    -6.615319   \n",
       "25%      -0.306885    -0.261664    -0.506588    -0.286805    -0.346466   \n",
       "50%       0.000000    -0.001913     0.003181     0.008339    -0.007045   \n",
       "75%       0.373598     0.354352     0.393931     0.463040     0.452260   \n",
       "max    1789.264038   192.869949   344.349670   618.762756    80.971764   \n",
       "\n",
       "       feature_149  feature_150  feature_151       rating  normed_rating  \n",
       "count  6486.000000  6486.000000  6486.000000  6486.000000    6486.000000  \n",
       "mean      0.122311     0.126640   231.566921     3.499075       0.318098  \n",
       "std      47.460380     1.560399     7.289107     1.115911       0.101446  \n",
       "min   -2797.750244    -6.860989   215.350998     1.000000       0.090909  \n",
       "25%      -0.617545    -0.391814   226.421005     3.000000       0.272727  \n",
       "50%      -0.064847    -0.000584   233.546005     3.000000       0.272727  \n",
       "75%       0.468566     0.481544   237.432999     4.000000       0.363636  \n",
       "max    1347.325928    30.387802   242.839005    10.000000       0.909091  \n",
       "\n",
       "[8 rows x 154 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: lightgbm in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in /Users/Ryo/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.7.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Regression Results\n",
      "Decision Tree       : Accuracy=0.3750  MSE=0.0145\n",
      "Random Forest       : Accuracy=0.5227  MSE=0.0057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import Hypers\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'k-NN (k=1)': KNeighborsRegressor(n_neighbors=1),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=RANDOM_SEED, verbose=-1)\n",
    "}\n",
    "\n",
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df = load_data('./data/train_dict_RetInd.pkl')\n",
    "test_df = load_data('./data/test_dict_RetInd.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import Hypers\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'k-NN (k=1)': KNeighborsRegressor(n_neighbors=1),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=RANDOM_SEED, verbose=-1)\n",
    "}\n",
    "\n",
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df = load_data('./data/train_dict_US.pkl')\n",
    "test_df = load_data('./data/test_dict_US.pkl')\n",
    "\n",
    "X_train = train_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_train = train_df['normed_rating']\n",
    "labels_train = train_df['rating']\n",
    "X_test = test_df.drop(columns=['company', 'period', 'rating', 'normed_rating'])\n",
    "y_test = test_df['normed_rating']\n",
    "labels_test = test_df['rating']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import Hypers\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'k-NN (k=1)': KNeighborsRegressor(n_neighbors=1),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_SEED),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=RANDOM_SEED, verbose=-1)\n",
    "}\n",
    "\n",
    "print('Train-Test Split Regression Results')\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_rounded = np.round(y_pred * (len(Hypers.rating_to_category) - 1)).astype(int)\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, 23)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = accuracy_score(labels_test, y_pred_rounded)\n",
    "\n",
    "    print(f'{model_name:20}: Accuracy={accuracy:.4f}  MSE={mse:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
